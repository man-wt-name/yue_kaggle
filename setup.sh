#!/bin/bash

#-----------------------------------------------------------------------------------------
# setup.sh: –ü–û–õ–ù–´–ô —Å–∫—Ä–∏–ø—Ç —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ Yue-Kaggle –≤ —Å—Ä–µ–¥–µ Kaggle/Colab.
#
# –í–µ—Ä—Å–∏—è 2.0: –í–∫–ª—é—á–∞–µ—Ç –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏–∑ Dockerfile (apt-get, conda, pip)
# –∏ –ª–æ–≥–∏–∫—É —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π –∏–∑ entrypoint.sh.
#
# –ü–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º:
# –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã –í–†–£–ß–ù–£–Æ —Å–æ–∑–¥–∞–ª–∏ –æ–∫—Ä—É–∂–µ–Ω–∏–µ Conda:
# > conda create -n pyenv python=3.12 -y
#
# –î–µ–π—Å—Ç–≤–∏—è —Å–∫—Ä–∏–ø—Ç–∞:
# 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ apt-get.
# 2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π Conda –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–µ 'pyenv'.
# 3. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π Pip –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–µ 'pyenv'.
# 4. –°–∫–∞—á–∏–≤–∞–Ω–∏–µ AI-–º–æ–¥–µ–ª–µ–π —Å Hugging Face.
# 5. –ü–∞—Ç—á–∏–Ω–≥ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ 'transformers' –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏.
# 6. –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ 'env_vars.sh' –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.
#-----------------------------------------------------------------------------------------

# --- –ù–ê–°–¢–†–û–ô–ö–ê ---
# –ü—Ä–µ—Ä—ã–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å–∫—Ä–∏–ø—Ç–∞ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
set -e
# –ù–∞–∑–≤–∞–Ω–∏–µ –≤–∞—à–µ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è Conda
CONDA_ENV_NAME="pyenv"
# –ö–∞–∫–∏–µ –º–æ–¥–µ–ª–∏ —Å–∫–∞—á–∏–≤–∞—Ç—å? –í–∞—Ä–∏–∞–Ω—Ç—ã:
# "all_bf16", "all_int8", "all_nf4", "all", "false"
# –∏–ª–∏ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é, –Ω–∞–ø—Ä–∏–º–µ—Ä "YuE-s2-1B-general,YuE-upsampler"
DOWNLOAD_MODELS="false"
# –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –º–æ–¥–µ–ª–µ–π
MODEL_DIR="/kaggle/working/models"
# –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
REPO_DIR="/kaggle/working/yue_kaggle"
HF_TOKEN="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"

# --- –®–ê–ì 1: –£–°–¢–ê–ù–û–í–ö–ê –°–ò–°–¢–ï–ú–ù–´–• –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô (APT-GET) ---
echo "===== –®–ê–ì 1: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ apt-get... ====="
sudo apt-get update -y
sudo apt-get install -y --no-install-recommends \
    wget bzip2 ca-certificates git curl build-essential cmake jq \
    libcurl4-openssl-dev libglib2.0-0 libgl1-mesa-glx libsm6 libssl-dev \
    libxext6 libxrender-dev software-properties-common openssh-server \
    openssh-client git-lfs vim zip unzip zlib1g-dev libc6-dev
# –û—á–∏—Å—Ç–∫–∞
sudo apt-get clean
sudo rm -rf /var/lib/apt/lists/*
# –ê–∫—Ç–∏–≤–∞—Ü–∏—è git-lfs
git lfs install
echo "===== –°–∏—Å—Ç–µ–º–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã. ====="
echo

# --- –®–ê–ì 2: –£–°–¢–ê–ù–û–í–ö–ê –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô CONDA ---
echo "===== –®–ê–ì 2: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π Conda –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–µ '$CONDA_ENV_NAME'... ====="
# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –æ–∫—Ä—É–∂–µ–Ω–∏—è
if ! conda info --envs | grep -q "^$CONDA_ENV_NAME\s"; then
    echo "–û–®–ò–ë–ö–ê: –û–∫—Ä—É–∂–µ–Ω–∏–µ Conda '$CONDA_ENV_NAME' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."
    echo "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–æ–∑–¥–∞–π—Ç–µ –µ–≥–æ –≤—Ä—É—á–Ω—É—é: conda create -n $CONDA_ENV_NAME python=3.12 -y"
    exit 1
fi
conda install -n $CONDA_ENV_NAME -c conda-forge openmpi mpi4py -y
conda install -n $CONDA_ENV_NAME -c nvidia cuda-nvcc -y
echo "===== –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ Conda —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã. ====="
echo

# --- –®–ê–ì 3: –£–°–¢–ê–ù–û–í–ö–ê –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô PIP ---
echo "===== –®–ê–ì 3: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π Pip –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–µ '$CONDA_ENV_NAME'... ====="
# PyTorch –¥–ª—è CUDA 12.4 (–≤–µ—Ä—Å–∏–∏ –∏–∑ Dockerfile)
conda run -n $CONDA_ENV_NAME pip install torch==2.5.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
# Jupyter –∏ Hugging Face Hub
#conda run -n $CONDA_ENV_NAME pip install jupyterlab ipywidgets jupyter-archive jupyter_contrib_nbextensions nodejs "huggingface_hub[cli]"
# –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –ø—Ä–æ–µ–∫—Ç–∞
if [ -f "requirements.txt" ]; then
    conda run -n $CONDA_ENV_NAME pip install --no-cache-dir -r requirements.txt
else
    echo "–û–®–ò–ë–ö–ê: –§–∞–π–ª requirements.txt –Ω–µ –Ω–∞–π–¥–µ–Ω!"
    exit 1
fi
echo "===== –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ Pip —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã. ====="
echo

# --- –®–ê–ì 4: –°–ö–ê–ß–ò–í–ê–ù–ò–ï –ú–û–î–ï–õ–ï–ô ---
echo "===== –®–ê–ì 4: –°–∫–∞—á–∏–≤–∞–Ω–∏–µ AI-–º–æ–¥–µ–ª–µ–π... ====="
if [[ -n "${HF_TOKEN}" ]]; then
    echo "–û–±–Ω–∞—Ä—É–∂–µ–Ω —Ç–æ–∫–µ–Ω HF_TOKEN. –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤—Ö–æ–¥ –≤ Hugging Face CLI..."
    conda run -n $CONDA_ENV_NAME huggingface-cli login --token ${HF_TOKEN}
fi

# –õ–æ–≥–∏–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π, –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∏–∑ entrypoint.sh
# --- –°–∫–∞—á–∏–≤–∞–Ω–∏–µ xcodec ---
XCODEC_DIR="${REPO_DIR}/inference/xcodec_mini_infer"
if [ ! -d "$XCODEC_DIR" ]; then
    echo "–°–∫–∞—á–∏–≤–∞–Ω–∏–µ xcodec_mini_infer..."
    conda run -n $CONDA_ENV_NAME huggingface-cli download m-a-p/xcodec_mini_infer --local-dir "$XCODEC_DIR"
else
    echo "–ú–æ–¥–µ–ª—å xcodec_mini_infer —É–∂–µ —Å–∫–∞—á–∞–Ω–∞."
fi

# --- –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π ---
declare -A MODELS_BF16
MODELS_BF16["YuE-s1-7B-anneal-en-cot"]="m-a-p/YuE-s1-7B-anneal-en-cot:${MODEL_DIR}/YuE-s1-7B-anneal-en-cot"
MODELS_BF16["YuE-s1-7B-anneal-en-icl"]="m-a-p/YuE-s1-7B-anneal-en-icl:${MODEL_DIR}/YuE-s1-7B-anneal-en-icl"
MODELS_BF16["YuE-s2-1B-general"]="m-a-p/YuE-s2-1B-general:${MODEL_DIR}/YuE-s2-1B-general"
MODELS_BF16["YuE-upsampler"]="m-a-p/YuE-upsampler:${MODEL_DIR}/YuE-upsampler"
# (–î–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –Ω–µ –≤—Å–µ –º–æ–¥–µ–ª–∏, –º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å –ø–æ –∞–Ω–∞–ª–æ–≥–∏–∏ —Å entrypoint.sh)

if [ "$DOWNLOAD_MODELS" != "false" ]; then
    echo "–í—ã–±—Ä–∞–Ω–∞ –æ–ø—Ü–∏—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: $DOWNLOAD_MODELS"
    SELECTED_MODELS=()
    MODELS=()

    if [ "$DOWNLOAD_MODELS" = "all_bf16" ]; then
        SELECTED_MODELS=("${!MODELS_BF16[@]}")
        for key in "${!MODELS_BF16[@]}"; do MODELS[$key]="${MODELS_BF16[$key]}"; done
    # –î–æ–±–∞–≤—å—Ç–µ –∑–¥–µ—Å—å elif –¥–ª—è all_int8, all_nf4, all –ø–æ –∞–Ω–∞–ª–æ–≥–∏–∏ —Å entrypoint.sh, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    else
        IFS=',' read -r -a SELECTED_MODELS <<< "$DOWNLOAD_MODELS"
        for MODEL in "${SELECTED_MODELS[@]}"; do
            if [[ -v MODELS_BF16[$MODEL] ]]; then MODELS[$MODEL]="${MODELS_BF16[$MODEL]}"; fi
        done
    fi

    for MODEL in "${SELECTED_MODELS[@]}"; do
        SOURCE_DEST_STRING=${MODELS[$MODEL]}
        if [[ -z "$SOURCE_DEST_STRING" ]]; then
            echo "–í–ù–ò–ú–ê–ù–ò–ï: –ú–æ–¥–µ–ª—å '$MODEL' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Å–ø–∏—Å–∫–∞—Ö. –ü—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è."
            continue
        fi
        SOURCE=$(echo $SOURCE_DEST_STRING | cut -d':' -f1)
        DESTINATION=$(echo $SOURCE_DEST_STRING | cut -d':' -f2)

        if [ ! -d "$DESTINATION" ]; then
            echo "–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏: $MODEL –∏–∑ $SOURCE..."
            conda run -n $CONDA_ENV_NAME huggingface-cli download "$SOURCE" --local-dir "$DESTINATION"
        else
            echo "–ú–æ–¥–µ–ª—å $MODEL —É–∂–µ —Å–∫–∞—á–∞–Ω–∞ –≤ $DESTINATION."
        fi
    done
else
    echo "–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø—Ä–æ–ø—É—â–µ–Ω–æ (DOWNLOAD_MODELS=false)."
fi
echo "===== –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–æ. ====="
echo

# --- –®–ê–ì 5: –ü–ê–¢–ß–ò–ù–ì –ë–ò–ë–õ–ò–û–¢–ï–ö–ò TRANSFORMERS ---
#echo "===== –®–ê–ì 5: –ü–∞—Ç—á–∏–Ω–≥ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ 'transformers'... ====="
#SITE_PACKAGES_DIR=$(conda run -n $CONDA_ENV_NAME python -c "import site; print(site.getsitepackages()[0])")
#TRANSFORMERS_PATH="$SITE_PACKAGES_DIR/transformers"

#if [ ! -d "$TRANSFORMERS_PATH" ]; then
    #echo "–û–®–ò–ë–ö–ê: –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ 'transformers' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å."
    #exit 1
#fi

#CUSTOM_MODELING_LLAMA="transformers/models/llama/modeling_llama.py"
#CUSTOM_GENERATION_UTILS="transformers/generation/utils.py"
#TARGET_MODELING_LLAMA="$TRANSFORMERS_PATH/models/llama/modeling_llama.py"
#TARGET_GENERATION_UTILS="$TRANSFORMERS_PATH/generation/utils.py"

#echo "–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Å—Ç–æ–º–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤..."
#cp -v "$CUSTOM_MODELING_LLAMA" "$TARGET_MODELING_LLAMA"
#cp -v "$CUSTOM_GENERATION_UTILS" "$TARGET_GENERATION_UTILS"
#echo "===== –ü–∞—Ç—á–∏–Ω–≥ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω. ====="
#echo

# --- –®–ê–ì 6: –°–û–ó–î–ê–ù–ò–ï –§–ê–ô–õ–ê –° –ü–ï–†–ï–ú–ï–ù–ù–´–ú–ò –û–ö–†–£–ñ–ï–ù–ò–Ø ---
echo "===== –®–ê–ì 6: –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ env_vars.sh... ====="
cat << EOF > env_vars.sh
#!/bin/bash
# –ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ —ç—Ç–æ—Ç —Ñ–∞–π–ª –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: source env_vars.sh
echo "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è..."
export REPO_DIR="${REPO_DIR}"
export MODEL_DIR="${MODEL_DIR}"
export PATH="\$REPO_DIR:\$REPO_DIR/inference:\$REPO_DIR/inference/xcodec_mini_infer:\$REPO_DIR/inference/xcodec_mini_infer/descriptaudiocodec:\$PATH"
echo "–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ \$PATH."
EOF
echo "–§–∞–π–ª env_vars.sh —Å–æ–∑–¥–∞–Ω."
echo

echo "=================================================================="
echo "      üöÄ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–≤–µ—Ä—à–µ–Ω—ã! üöÄ     "
echo "=================================================================="
echo "–î–ê–õ–¨–ù–ï–ô–®–ò–ï –î–ï–ô–°–¢–í–ò–Ø:"
echo
echo "1. –ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (–Ω—É–∂–Ω–æ –¥–µ–ª–∞—Ç—å –≤ –ö–ê–ñ–î–û–ô –Ω–æ–≤–æ–π —Å–µ—Å—Å–∏–∏ —Ç–µ—Ä–º–∏–Ω–∞–ª–∞):"
echo "   source env_vars.sh"
echo
echo "2. –ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ Conda (–µ—Å–ª–∏ –µ—â–µ –Ω–µ –∞–∫—Ç–∏–≤–Ω–æ):"
echo "   conda activate $CONDA_ENV_NAME"
echo
echo "3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å:"
echo "   python inference/interface.py"
echo "------------------------------------------------------------------"